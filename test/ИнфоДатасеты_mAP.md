
# Распределение изображений по классам в датасетах ImageNet и COCO

## ImageNet

- **Общее количество изображений:** 14,197,122
- **Количество классов:** 1000
- **Среднее количество изображений на класс:** ~14,197

Примечание: Количество изображений в каждом классе может варьироваться, но в среднем для каждого класса доступно около 14,200 изображений.

## COCO

- **Общее количество изображений:** 328,000
- **Количество классов:** 80
- **Среднее количество изображений на класс:** ~4,100

Примечание: Количество изображений в каждом классе может варьироваться, но в среднем для каждого класса доступно около 4,100 изображений.

В офицальных источниках [COCO](https://cocodataset.org/#home) и [ImageNet](https://www.image-net.org/) указано, что соблюдалось нормальное распеределение изображений по классам, однако (особенно ImageNet) возможны случаи отклонения. Также важно понимать, что датасеты наполнены "пустыми" изображениями без меток (в COCO порядка 120к таких изображений), а также в статистику включены валидационные и тестовые изображения. Поэтому, реальное количество размеченных изображений в каждом классе меньше.

---

# Метрики mAP50 и mAP50-95

## Введение

**Mean Average Precision (mAP)** — это метрика, используемая для оценки качества моделей детекции объектов. mAP объединяет два показателя: точность (**Precision**) и полноту (**Recall**). Она основана на значении другой метрики **IoU** (Intersection over Union).

**IoU** указывает, насколько сильно перекрываются ограничивающие рамки. Этот коэффициент перекрытия между областями двух ограничивающих рамок равен 1.0 в случае точного совпадения и 0.0, если перекрытия нет.

### Precision и Recall

   ![Precision](https://camo.githubusercontent.com/fe40cc829b830850a3afec84988af7f49aad247a4c185ae1d695a3aacde1679c/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f25354374657874253742507265636973696f6e253744253230253344253230253543667261632537422535437465787425374254502537442537442537422535437465787425374254502537442b2535437465787425374246502537442537442533442535436672616325374225354374657874253742545025374425374425374225354374657874253742616c6c253230646574656374696f6e73253744253744)

   ![Recall](https://camo.githubusercontent.com/eb3313a4247de12c69e7757100c9291ab8894bc1c3cb1f5eedf18bd68e9e605a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f25354374657874253742526563616c6c253744253230253344253230253543667261632537422535437465787425374254502537442537442537422535437465787425374254502537442b25354374657874253742464e2537442537442533442535436672616325374225354374657874253742545025374425374425374225354374657874253742616c6c25323067726f756e64253230747275746873253744253744)

### IoU

   ![IoU](https://camo.githubusercontent.com/01ff10da086e1e55f3a9ab3834bfc77cd28632c16995b3b26baa7127bdce9e15/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f25354374657874253742494f552537442533442535436672616325374225354374657874253742617265612537442535436c656674253238425f25374270253744253230253543636170253230425f2537426774253744253230253543726967687425323925374425374225354374657874253742617265612537442535436c656674253238425f25374270253744253230253543637570253230425f25374267742537442532302535437269676874253239253744)

   ![IoU](https://github.com/rafaelpadilla/Object-Detection-Metrics/blob/master/aux_images/iou.png)

## mAP@50 и mAP@50-95

**mAP@50** и **mAP@50-95** являются наиболее распространенными вариациями данной метрики. В частности, в бенчмарках [YOLO](https://docs.ultralytics.com/ru/guides/yolo-performance-metrics/#introduction) используется **mAP@50-95**, а при обучении также оценивается **mAP@50**

- **mAP@50**: mAP, вычисленный при пороговом значении **IoU** равном 0.5.
- **mAP@50-95**: усреднённый mAP, вычисленный по нескольким порогам **IoU** от 0.5 до 0.95 с шагом 0.05.

Более подробная информация по различным метрикам YOLO и интерпритации их результатов описана в **Шаги обучения моделей**.
