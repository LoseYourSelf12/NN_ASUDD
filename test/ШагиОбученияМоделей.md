
# Основные шаги обучения модели YOLOv8

## Шаг 0. Подготовка датасета

Данный шаг должен быть расписан более подробно, однако, основные моменты можно описать так:

- **Размер датасета.** Датасет должен в достаточной мере описывать возможные вариации объектов интереса. В среднем, для лучшего результата 2000 меток на один класс и его вариацию является достаточным, но не исчерпывающим вариантом;
- **Качество разметки.** Качество разметки данных играет ключевую роль в дальнейшей точности модели, особенно в ситуациях, когда позиционирование играет важную роль;
- **Распределение и наполнение.** Грамотное распределение выборки на обучающую, валидационную и тестовую имеет большое значение. Также не малую роль играет наполнение датасета "пустыми" изображениями, а также некоторой частью синтетических данных.

## Шаг 1. Подбор гиперапараметров

Данный этап является наиболее ответственным, т.к. не в малой мере определяет, какая получится модель и сколько ресурсов на это потребуется.

Список всех гиперпараметров обучения YOLO, а также их описание можно посмотреть [по этой ссылке](https://docs.ultralytics.com/ru/modes/train/#resuming-interrupted-trainings). Ключевыми являются следующие:
- `epochs` - количество эпох обучения;
- `imgsz` - размер входного изображения;
- `batch` - размер батча обучения;
- `patience` - остановка обучения, если нет улучшения показателей.

Есть два варианта:

1. Ручной подбор

Если модель является тестовой или используется в экспериментах, то перемешивание всех параметров не имеет смысла. Можно установить только ключевые параметры.
Тонкость настройки даже в ручном методе имеет значение. К примеру, установка слишком большого значения `epochs` может привести к переобучения модели, а также большим тратам времени. Этот параметр лучше использовать в паре с `patience`, который вовремя остановит обучения. Большой размер `batch` может привести к перегрузке системы, а также неоптимальной работе модели в последствии. В свою очередь, `imgsz` лучше выставлять в соответствии с размерами будущих входных изображений, в ином случае, точность модели пострадает. 

2. Автоматический подбор

В данном случае, процесс более сложный и требует пердварительной подготовки. Более подробное описание настройки автоматического подбора описано [в этой статье](https://docs.ultralytics.com/ru/guides/hyperparameter-tuning/#tune_scatter_plotspng) и [в этой статье](https://docs.ultralytics.com/ru/integrations/ray-tune/#tune-method-parameters).

Все происходит с помощью метода `model.tune()`. Он использует модели мутации и эволюции параметров модели. На выходе получается YAML файл с наилучшими подобранными параметрами.
При инициализации метода `tune()` также задаются основные параметры:
- `data` - Файл конфигурации набора данных (в формате YAML)
- `epochs` - Количество эпох на одну итерацию
- `space` - Словарь, определяющий пространство поиска гиперпараметров
- `grace_period` - Минимальное количество эпох на одну итерацию
- `iterations` - Максимальное количество итераций
- `use_ray` - Использование Ray Tune

В результате получаем что-то вроде:

```
from ultralytics import YOLO

model = YOLO("yolov8n.pt")

result_grid = model.tune(
    data="coco8.yaml",
    space={"lr0": tune.uniform(1e-5, 1e-1)},
    epochs=50,
    use_ray=True,
)
```

## Шаг 2. Обучение

В шаге 1 уже частично описан процесс обучения YOLO. Определив переменные с путями к датасету, определив гиперапараметры приступаем к самому обучению. Все происходит с помощью метода `train()`, куда мы передаем конфигурационные файл YAML, а также некоторые параметры.

Пример скрипта:

```
from ultralytics import YOLO

# Загрузка модели 
model = YOLO("yolov8n.yaml")  # построение новой модели из YAML
model = YOLO("yolov8n.pt")  # загрузка предобученной модели (рекомендуется)
model = YOLO("yolov8n.yaml").load("yolov8n.pt")  # построение новой модели из YAML и трансфер весов

# Обучение модели
results = model.train(data="coco8.yaml", epochs=100, imgsz=640)
```

## Шаг 3. Результат

Помимо самих обученных весов (best.pt и last.pt), мы получаем различные графики и метрики процесса обучения. Если с весами все понятно, то что делать с метриками?

Первым делом, необходимо разбить вывод функции `model.val()`. Эта подробная информация полезна, когда ты пытаешься понять, насколько хорошо модель справляется с каждым конкретным классом, особенно в наборах данных с разнообразными категориями объектов. Для каждого класса в наборе данных предоставляется следующее:

- **Класс** - Здесь обозначается название класса объекта.
- **Изображения** - Эта метрика говорит о количестве изображений в наборе для проверки.
- **Экземпляры** - Здесь указывается, сколько раз данный класс встречается на всех изображениях в наборе для проверки.
- **Box(P, R, mAP50, mAP50-95)** - Эта метрика дает представление о производительности модели в обнаружении объектов:
    - **P (Precision)** - Точность обнаруженных объектов, показывающая, сколько обнаружений были правильными.
    - **R (Recall)** - Способность модели идентифицировать все экземпляры объектов на изображениях.
    - **mAP50** - Средняя точность, рассчитанная при пороге intersection over union (IoU), равном 0,50. Это показатель точности модели, учитывающей только "легкие" обнаружения.
    - **mAP50-95** - Среднее значение средней точности, рассчитанное при различных пороговых значениях IoU, варьирующихся от 0,50 до 0,95. Оно дает полное представление о производительности модели на разных уровнях сложности обнаружения.

Функция `model.val()`, помимо числовых показателей, также выдает визуальные результаты, которые могут дать более интуитивное понимание работы модели.

**Некоторое интерпретирование метрик:**

- **Низкий показатель mAP** - Указывает на то, что модель может нуждаться в общих доработках.
- **Низкий IoU** - возможно, модель с трудом справляется с точным определением объектов.
- **Низкая точность (Precision)** - Возможно, модель обнаруживает слишком много несуществующих объектов. Регулировка порогов доверия может снизить этот показатель.
- **Низкий Recall** - Модель может пропускать реальные объекты. Улучшение извлечения признаков или использование большего количества данных может помочь.
- **Несбалансированный F1 Score** - Существует диспропорция между precision и recall.

## Шаг 4. Экспорт

Данный шаг не является обязательным, однако, не упомянуть о нем нельзя. [Ultralytics](https://docs.ultralytics.com/ru/modes/export/#key-features-of-export-mode) предоставляет удобные способы экспорта модели в любой другой популярный формат.

О всех возможных форматах экспорта можно ознакомиться в статье по ссылке сверху.

Пример экспорта в формат ONNX и TensorRT:

```
from ultralytics import YOLO

# Загрузка модели
model = YOLO("yolov8n.pt")  # предобученные веса
model = YOLO("path/to/best.pt")  # кастомные веса

# Экспорт модели
model.export(format="onnx") # экспорт в ONNX формат без изменения структуры весов
model.export(format="engine", imgsz=320, int8=True, batch=4) # экспорт в TensorRT формат с изменением структуры весов
```

## Шаг 5. Вы молодец!